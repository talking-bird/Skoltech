{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af15007e",
   "metadata": {
    "id": "approved-psychology"
   },
   "source": [
    "# Home Assignment No. 2 - part one\n",
    "\n",
    "To solve this task, you will write a lot of code to try several machine learning methods for classification and regression.\n",
    "* You are **HIGHLY RECOMMENDED** to read relevant documentation, e.g. for [python](https://docs.python.org/3/), [numpy](https://docs.scipy.org/doc/numpy/reference/), [matlpotlib](https://matplotlib.org/) and [sklearn](https://scikit-learn.org/stable/). Also remember that seminars, lecture slides, [Google](http://google.com) and [StackOverflow](https://stackoverflow.com/) are your close friends during this course (and, probably, whole life?).\n",
    "\n",
    "* If you want an easy life, you have to use **BUILT-IN METHODS** of `sklearn` library instead of writing tons of your own code. There exists a class/method for almost everything you can imagine (related to this homework).\n",
    "\n",
    "* You have to write **CODE** directly inside specified places marked by comments: **BEGIN/END Solution**. Do not create new cells.\n",
    "\n",
    "* In some problems you are asked to provide a short discussion of the results. For that find the specific place marked via **Your text answer: \\<write your answer\\>**.\n",
    "\n",
    "* For every separate problem or subproblem (if specified) you can get only 0 points or maximal points for this problem. There are **NO INTERMEDIATE scores**. So make sure that you did everything required in the task.\n",
    "\n",
    "* Your **SOLUTION** notebook **MUST BE REPRODUCIBLE**, i.e., if the reviewer decides to restart the notebook and run all cells, after all the computation he will obtain exactly the same solution (with all the corresponding plots) as in your uploaded notebook. For this purpose, we suggest fixing random `seed` or (better) define `random_state=` inside every algorithm that uses some pseudorandomness.\n",
    "\n",
    "* Your code must be clear to the reviewer. For this purpose, try to include necessary comments inside the code. But remember: **GOOD CODE MUST BE SELF-EXPLANATORY** without any additional comments.\n",
    "\n",
    "* Many `sklearn` algorithms support multithreading (Ensemble Methods, Cross-Validation, etc.). Check if the particular algorithm has `n_jobs` parameters and set it to `-1` to use all the cores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea37c86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:18.450218Z",
     "start_time": "2022-03-06T13:01:16.308768Z"
    },
    "id": "cooperative-spokesman"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189f8726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:18.481224Z",
     "start_time": "2022-03-06T13:01:18.468214Z"
    },
    "id": "noted-bridal"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260daf9",
   "metadata": {
    "id": "guilty-contamination"
   },
   "source": [
    "## Task 1. Model and feature selection problem (3 points)\n",
    "\n",
    "Your goal in this task is to predict the price (```price_doc```) given some characteristics of a house. In order to do that, you will demonstrate your abilities in data preprocessing, finding feature importances, applying different ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae55732",
   "metadata": {
    "heading_collapsed": true,
    "id": "friendly-review"
   },
   "source": [
    "### Subproblem 1.1. Data preprocessing and feauture importances (1 point)\n",
    "\n",
    "The goal of this subproblem is to prepare the data for further usage. Complete all of the following subtasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b082aa",
   "metadata": {
    "hidden": true,
    "id": "rational-reggae"
   },
   "source": [
    "**1.1.1) load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee2a8e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:19.901758Z",
     "start_time": "2022-03-06T13:01:18.498218Z"
    },
    "hidden": true,
    "id": "nutritional-phoenix"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>provision_retail_space_modern_sqm</th>\n",
       "      <th>turnover_catering_per_cap</th>\n",
       "      <th>theaters_viewers_per_1000_cap</th>\n",
       "      <th>seats_theather_rfmin_per_100000_cap</th>\n",
       "      <th>museum_visitis_per_100_cap</th>\n",
       "      <th>bandwidth_sports</th>\n",
       "      <th>population_reg_sports_share</th>\n",
       "      <th>students_reg_sports_share</th>\n",
       "      <th>apartment_build</th>\n",
       "      <th>apartment_fund_sqm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>271.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.45356</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>269768.0</td>\n",
       "      <td>22.37</td>\n",
       "      <td>64.12</td>\n",
       "      <td>23587.0</td>\n",
       "      <td>230310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>44</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234576.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>86</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234576.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234576.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234576.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>43</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234576.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0      2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
       "1      2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
       "2      2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
       "3      2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
       "4      2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
       "...           ...      ...      ...    ...        ...       ...         ...   \n",
       "30466  2015-06-30       44     27.0    7.0        9.0       1.0      1975.0   \n",
       "30467  2015-06-30       86     59.0    3.0        9.0       2.0      1935.0   \n",
       "30468  2015-06-30       45      NaN   10.0       20.0       1.0         NaN   \n",
       "30469  2015-06-30       64     32.0    5.0       15.0       1.0      2003.0   \n",
       "30470  2015-06-30       43     28.0    1.0        9.0       1.0      1968.0   \n",
       "\n",
       "       num_room  kitch_sq  state  ... provision_retail_space_modern_sqm  \\\n",
       "0           NaN       NaN    NaN  ...                             271.0   \n",
       "1           NaN       NaN    NaN  ...                             271.0   \n",
       "2           NaN       NaN    NaN  ...                             271.0   \n",
       "3           NaN       NaN    NaN  ...                             271.0   \n",
       "4           NaN       NaN    NaN  ...                             271.0   \n",
       "...         ...       ...    ...  ...                               ...   \n",
       "30466       2.0       6.0    3.0  ...                               NaN   \n",
       "30467       4.0      10.0    3.0  ...                               NaN   \n",
       "30468       1.0       1.0    1.0  ...                               NaN   \n",
       "30469       2.0      11.0    2.0  ...                               NaN   \n",
       "30470       2.0       6.0    2.0  ...                               NaN   \n",
       "\n",
       "      turnover_catering_per_cap  theaters_viewers_per_1000_cap  \\\n",
       "0                        6943.0                          565.0   \n",
       "1                        6943.0                          565.0   \n",
       "2                        6943.0                          565.0   \n",
       "3                        6943.0                          565.0   \n",
       "4                        6943.0                          565.0   \n",
       "...                         ...                            ...   \n",
       "30466                   10805.0                            NaN   \n",
       "30467                   10805.0                            NaN   \n",
       "30468                   10805.0                            NaN   \n",
       "30469                   10805.0                            NaN   \n",
       "30470                   10805.0                            NaN   \n",
       "\n",
       "       seats_theather_rfmin_per_100000_cap  museum_visitis_per_100_cap  \\\n",
       "0                                  0.45356                      1240.0   \n",
       "1                                  0.45356                      1240.0   \n",
       "2                                  0.45356                      1240.0   \n",
       "3                                  0.45356                      1240.0   \n",
       "4                                  0.45356                      1240.0   \n",
       "...                                    ...                         ...   \n",
       "30466                              0.45888                         NaN   \n",
       "30467                              0.45888                         NaN   \n",
       "30468                              0.45888                         NaN   \n",
       "30469                              0.45888                         NaN   \n",
       "30470                              0.45888                         NaN   \n",
       "\n",
       "       bandwidth_sports  population_reg_sports_share  \\\n",
       "0              269768.0                        22.37   \n",
       "1              269768.0                        22.37   \n",
       "2              269768.0                        22.37   \n",
       "3              269768.0                        22.37   \n",
       "4              269768.0                        22.37   \n",
       "...                 ...                          ...   \n",
       "30466          463938.0                          NaN   \n",
       "30467          463938.0                          NaN   \n",
       "30468          463938.0                          NaN   \n",
       "30469          463938.0                          NaN   \n",
       "30470          463938.0                          NaN   \n",
       "\n",
       "       students_reg_sports_share  apartment_build  apartment_fund_sqm  \n",
       "0                          64.12          23587.0            230310.0  \n",
       "1                          64.12          23587.0            230310.0  \n",
       "2                          64.12          23587.0            230310.0  \n",
       "3                          64.12          23587.0            230310.0  \n",
       "4                          64.12          23587.0            230310.0  \n",
       "...                          ...              ...                 ...  \n",
       "30466                        NaN              NaN            234576.9  \n",
       "30467                        NaN              NaN            234576.9  \n",
       "30468                        NaN              NaN            234576.9  \n",
       "30469                        NaN              NaN            234576.9  \n",
       "30470                        NaN              NaN            234576.9  \n",
       "\n",
       "[30471 rows x 390 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "df = pd.read_csv(\"data_fs.csv\", sep=',')\n",
    "df\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93109f47",
   "metadata": {
    "hidden": true,
    "id": "objective-working"
   },
   "source": [
    "**1.1.2) preprocess the dataset by dropping the ```timestamp``` feature, filling ```NaN```s with 0, converting the categorical variables into dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedc7ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:20.233721Z",
     "start_time": "2022-03-06T13:01:19.949795Z"
    },
    "hidden": true,
    "id": "another-keyboard"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>state</th>\n",
       "      <th>area_m</th>\n",
       "      <th>...</th>\n",
       "      <th>child_on_acc_pre_school_3,013</th>\n",
       "      <th>child_on_acc_pre_school_7,311</th>\n",
       "      <th>modern_education_share_0</th>\n",
       "      <th>modern_education_share_90,92</th>\n",
       "      <th>modern_education_share_93,08</th>\n",
       "      <th>modern_education_share_95,4918</th>\n",
       "      <th>old_education_build_share_0</th>\n",
       "      <th>old_education_build_share_23,14</th>\n",
       "      <th>old_education_build_share_25,47</th>\n",
       "      <th>old_education_build_share_8,2517</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.407578e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.589337e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.808270e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.258354e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.398461e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30466</th>\n",
       "      <td>44</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.005305e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30467</th>\n",
       "      <td>86</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.307411e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30468</th>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.553630e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30469</th>\n",
       "      <td>64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.050065e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>43</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.395333e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30471 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  material  build_year  num_room  \\\n",
       "0           43     27.0    4.0        0.0       0.0         0.0       0.0   \n",
       "1           34     19.0    3.0        0.0       0.0         0.0       0.0   \n",
       "2           43     29.0    2.0        0.0       0.0         0.0       0.0   \n",
       "3           89     50.0    9.0        0.0       0.0         0.0       0.0   \n",
       "4           77     77.0    4.0        0.0       0.0         0.0       0.0   \n",
       "...        ...      ...    ...        ...       ...         ...       ...   \n",
       "30466       44     27.0    7.0        9.0       1.0      1975.0       2.0   \n",
       "30467       86     59.0    3.0        9.0       2.0      1935.0       4.0   \n",
       "30468       45      0.0   10.0       20.0       1.0         0.0       1.0   \n",
       "30469       64     32.0    5.0       15.0       1.0      2003.0       2.0   \n",
       "30470       43     28.0    1.0        9.0       1.0      1968.0       2.0   \n",
       "\n",
       "       kitch_sq  state        area_m  ...  child_on_acc_pre_school_3,013  \\\n",
       "0           0.0    0.0  6.407578e+06  ...                              0   \n",
       "1           0.0    0.0  9.589337e+06  ...                              0   \n",
       "2           0.0    0.0  4.808270e+06  ...                              0   \n",
       "3           0.0    0.0  1.258354e+07  ...                              0   \n",
       "4           0.0    0.0  8.398461e+06  ...                              0   \n",
       "...         ...    ...           ...  ...                            ...   \n",
       "30466       6.0    3.0  1.005305e+07  ...                              0   \n",
       "30467      10.0    3.0  7.307411e+06  ...                              0   \n",
       "30468       1.0    1.0  2.553630e+07  ...                              0   \n",
       "30469      11.0    2.0  6.050065e+06  ...                              0   \n",
       "30470       6.0    2.0  4.395333e+06  ...                              0   \n",
       "\n",
       "       child_on_acc_pre_school_7,311  modern_education_share_0  \\\n",
       "0                                  0                         1   \n",
       "1                                  0                         1   \n",
       "2                                  0                         1   \n",
       "3                                  0                         1   \n",
       "4                                  0                         1   \n",
       "...                              ...                       ...   \n",
       "30466                              0                         0   \n",
       "30467                              0                         0   \n",
       "30468                              0                         0   \n",
       "30469                              0                         0   \n",
       "30470                              0                         0   \n",
       "\n",
       "       modern_education_share_90,92  modern_education_share_93,08  \\\n",
       "0                                 0                             0   \n",
       "1                                 0                             0   \n",
       "2                                 0                             0   \n",
       "3                                 0                             0   \n",
       "4                                 0                             0   \n",
       "...                             ...                           ...   \n",
       "30466                             0                             0   \n",
       "30467                             0                             0   \n",
       "30468                             0                             0   \n",
       "30469                             0                             0   \n",
       "30470                             0                             0   \n",
       "\n",
       "       modern_education_share_95,4918  old_education_build_share_0  \\\n",
       "0                                   0                            1   \n",
       "1                                   0                            1   \n",
       "2                                   0                            1   \n",
       "3                                   0                            1   \n",
       "4                                   0                            1   \n",
       "...                               ...                          ...   \n",
       "30466                               1                            0   \n",
       "30467                               1                            0   \n",
       "30468                               1                            0   \n",
       "30469                               1                            0   \n",
       "30470                               1                            0   \n",
       "\n",
       "       old_education_build_share_23,14  old_education_build_share_25,47  \\\n",
       "0                                    0                                0   \n",
       "1                                    0                                0   \n",
       "2                                    0                                0   \n",
       "3                                    0                                0   \n",
       "4                                    0                                0   \n",
       "...                                ...                              ...   \n",
       "30466                                0                                0   \n",
       "30467                                0                                0   \n",
       "30468                                0                                0   \n",
       "30469                                0                                0   \n",
       "30470                                0                                0   \n",
       "\n",
       "       old_education_build_share_8,2517  \n",
       "0                                     0  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  \n",
       "...                                 ...  \n",
       "30466                                 1  \n",
       "30467                                 1  \n",
       "30468                                 1  \n",
       "30469                                 1  \n",
       "30470                                 1  \n",
       "\n",
       "[30471 rows x 561 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "df0 = df.drop(columns='timestamp')\n",
    "df1 = df0.fillna(value=0)\n",
    "df2 = pd.get_dummies(df1)\n",
    "df2\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b26ce",
   "metadata": {
    "hidden": true,
    "id": "dress-shanghai"
   },
   "source": [
    "**1.1.3) define ```x_train```, ```x_test```, ```y_train```, ```y_test```. The train-test split should be 70:30**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2205b9dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:20.620730Z",
     "start_time": "2022-03-06T13:01:20.371716Z"
    },
    "hidden": true,
    "id": "outdoor-runner"
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "y = df2.price_doc\n",
    "X = df2.drop(columns='price_doc')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7,random_state=0xC0FFEE)\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bbda5",
   "metadata": {
    "hidden": true,
    "id": "engaging-ready"
   },
   "source": [
    "\n",
    "**1.1.4) plot the histogram of y values. Note that the mean of these values is very high and the distribution of the values is far from normal. Create ```y_train_log``` and ```y_test_log``` by applying $log_{y}$. Now plot the new histogram of the obtained values. You should use these log values for the next subtasks.**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f20b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:21.401446Z",
     "start_time": "2022-03-06T13:01:20.823620Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "for y in [y_train,y_train_log]:\n",
    "    plt.hist(y,bins=100)\n",
    "    plt.title('price_doc')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af70b5",
   "metadata": {
    "hidden": true,
    "id": "noticed-drunk"
   },
   "source": [
    "**1.1.5) print the number of features in the created ```x_train``` and ```x_test``` datasets. Answer the question: do you think all of these features are relevant for the adequate price prediction?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "555ce1d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:01:21.573401Z",
     "start_time": "2022-03-06T13:01:21.561385Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "strategic-spending",
    "outputId": "60227791-3f62-4d31-cbcd-a5a8aada6763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features  in X_train is 560\n",
      "number of features  in X_test is 560\n"
     ]
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "print(f\"number of features  in X_train is {X_train.shape[1]}\")\n",
    "print(f\"number of features  in X_test is {X_test.shape[1]}\")\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c798e41",
   "metadata": {
    "hidden": true,
    "id": "restricted-anchor"
   },
   "source": [
    "**Your text answer (do not delete this comment)**:\\\n",
    "I don't think all of this features are relevant for the adequate price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8a1c8",
   "metadata": {
    "hidden": true,
    "id": "endangered-mineral"
   },
   "source": [
    "**1.1.6) use random forest to find the importance of the features. Plot the histogram of the importances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62d259c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:02:53.384454Z",
     "start_time": "2022-03-06T13:01:22.207879Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(random_state=0xC0FFEE, n_jobs =-1)\n",
    "forest_reg.fit(X_train,y_train_log)\n",
    "importances = forest_reg.feature_importances_\n",
    "\n",
    "plt.hist(importances,bins=100)\n",
    "plt.show()\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c703a23",
   "metadata": {
    "hidden": true,
    "id": "ethical-firmware"
   },
   "source": [
    "**1.1.7) print the names of the 20 most important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15e6065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:02:53.807098Z",
     "start_time": "2022-03-06T13:02:53.543037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "amazing-marriage",
    "outputId": "53ab5987-aa41-43f6-816e-37580d1cff79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eurrub' 'workplaces_km' 'additional_education_km' 'ttk_km' 'floor'\n",
      " 'big_road1_km' 'micex' 'public_healthcare_km' 'cafe_count_5000'\n",
      " 'exhibition_km' 'brent' 'kindergarten_km' 'micex_cbi_tr' 'metro_km_avto'\n",
      " 'cafe_count_5000_price_2500' 'cafe_count_3000' 'sport_count_3000'\n",
      " 'cafe_count_2000' 'num_room' 'full_sq']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "importance_num = forest_reg.feature_importances_/np.sum(forest_reg.feature_importances_)\n",
    "importance = np.column_stack((importance_num, X_train.columns))\n",
    "importance = importance[np.argsort(importance[:,0])]\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.title(\"{} Feature Importances\".format(type(forest_reg).__name__), fontsize=20)\n",
    "plt.xlabel(\"Relative Importance\", fontsize=20)\n",
    "plt.barh(importance[-20:,1],importance[-20:,0])\n",
    "\n",
    "top20features = importance[-20:,1]\n",
    "print(top20features)\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e000b",
   "metadata": {
    "hidden": true,
    "id": "threaded-ivory"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e385937",
   "metadata": {
    "heading_collapsed": true,
    "id": "little-toddler"
   },
   "source": [
    "### Subproblem 1.2. Training models on the most important features (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0398d0",
   "metadata": {
    "hidden": true,
    "id": "vietnamese-patrick"
   },
   "source": [
    "In this subproblem, you will train several ML models on the found 20 most important features: train **Linear Regression**,  **Ridge regression**, **Random forest**,  **DecisionTree** and evaluate their performance using the Root Mean Squared Logarithmic Error (RMSLE) on both train/test sets. \n",
    "\n",
    "You will have to repeat the same actions in the next tasks too, so we recommend to implement\n",
    "a dedicated function for comparisons, which\n",
    "1. on input takes a training dataset `(X_train, y_train)` and a test sample `(X_test, y_test)`;\n",
    "2. it trains **all of the listed models** on the `(X_train, y_train)` sample;\n",
    "3. it computes and returns a table with the RMSLE score of each fitted model on the train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cd800",
   "metadata": {
    "hidden": true,
    "id": "stupid-principle"
   },
   "source": [
    "**1.2.1) Implement the function described above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad7c56e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:02:53.980232Z",
     "start_time": "2022-03-06T13:02:53.952121Z"
    },
    "hidden": true,
    "id": "paperback-uniform"
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "def comparison(X_train, y_train, X_test, y_test):\n",
    "    LR = LinearRegression()\n",
    "    lasso = Lasso(random_state = 0xC0FFEE)\n",
    "    ridge = Ridge(random_state = 0xC0FFEE)\n",
    "    RFR = RandomForestRegressor(random_state = 0xC0FFEE, n_jobs =-1)\n",
    "    dtree = DecisionTreeRegressor(random_state = 0xC0FFEE)\n",
    "    dictionary = {'Methods': ['Linear Regression','Lasso','Ridge','Dtree','RFR'], 'Train error': [0]*5, 'Test error': [0]*5 }\n",
    "    for i,clf in enumerate([LR,lasso, ridge, dtree, RFR]):\n",
    "        clf.fit(X_train,y_train)\n",
    "        \n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        dictionary['Test error'][i] = msle(y_test,y_test_pred, squared=True)\n",
    "        \n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        dictionary['Train error'][i] = msle(y_train,y_train_pred,squared=True)\n",
    "        \n",
    "    return pd.DataFrame(dictionary)\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a6c75",
   "metadata": {
    "hidden": true,
    "id": "demographic-honolulu"
   },
   "source": [
    "**1.2.2) Apply the implemented function to our dataset (use only the 20 most important features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babd9524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:03:00.366302Z",
     "start_time": "2022-03-06T13:02:54.139250Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Train error</th>\n",
       "      <th>Test error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.030271e-03</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.201120e-03</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.030270e-03</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>1.360209e-09</td>\n",
       "      <td>0.001748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFR</td>\n",
       "      <td>1.235163e-04</td>\n",
       "      <td>0.000910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Methods   Train error  Test error\n",
       "0  Linear Regression  1.030271e-03    0.001089\n",
       "1              Lasso  1.201120e-03    0.001240\n",
       "2              Ridge  1.030270e-03    0.001089\n",
       "3              Dtree  1.360209e-09    0.001748\n",
       "4                RFR  1.235163e-04    0.000910"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN Solution\n",
    "X_train_top20 = X_train.loc[:,top20features]\n",
    "X_test_top20 = X_test.loc[:,top20features]\n",
    "df = comparison(X_train_top20, y_train_log, X_test_top20, y_test_log)\n",
    "df\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460bd96",
   "metadata": {
    "hidden": true,
    "id": "6lSOGA4-7RSx"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d47ec",
   "metadata": {
    "id": "stock-jewel"
   },
   "source": [
    "### Subproblem 1.3. Forward-backward methods (1 point)\n",
    "In the subproblems above, we have relied on the feature importances found by the random forest method. The main goal of this subproblem is to find feature importances by applying the forward-backward methods: the main idea is to add or remove features and compute how this removal influences the value of the loss function or some other criteria.\n",
    "\n",
    "The decision about adding or deleting a feature may be made based on:\n",
    "\n",
    "- AIC\n",
    "- BIC\n",
    "- validation error\n",
    "- Mallows $C_p$\n",
    "- sklearn's `estimator.score()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c97919",
   "metadata": {
    "id": "southern-closer"
   },
   "source": [
    "In subtasks, 1.3.1 - 1.3.3, implement the following greedy feature selection algorithm with early stopping using the mean of the RMSLE scores achieved on the 3-fold cross-validation. Please bear in mind that **the lower** RMSLE (`mean_squared_log_error`) is, **the higher the model \"quality\" is** and look up `cross_val_score(...)` peculiarities in [scikit's manual](https://scikit-learn.org/stable/documentation.html) for more information.\n",
    "\n",
    "```python\n",
    "# Initialize with an empty list of features.\n",
    "list_of_best_features = []\n",
    "\n",
    "while round < n_rounds:\n",
    "    round = round + 1\n",
    "    \n",
    "    if no_more_features:\n",
    "        # end loop\n",
    "\n",
    "    # Iterate over currently *unused* features and use $k$-fold \n",
    "    # . `cross_val_score` to measure model \"quality\".\n",
    "    compute_quality_with_each_new_unused_feature(...)\n",
    "\n",
    "    # **Add** the feature that gives the highest \"quality\" of the model.\n",
    "    pick_and_add_the_best_feature(...)\n",
    "\n",
    "    if model_quality_has_increased_since_last_round:\n",
    "        round = 0\n",
    "\n",
    "return list_of_best_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734466d",
   "metadata": {
    "id": "suffering-italy"
   },
   "source": [
    "**1.3.1) In the cell below, you have to implement a function that would iterate over a list of features and use $k$-fold `cross_val_score` to measure the model's \"quality\".** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e558f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:03:00.696425Z",
     "start_time": "2022-03-06T13:03:00.681359Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9f64383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:03:00.869991Z",
     "start_time": "2022-03-06T13:03:00.854979Z"
    },
    "id": "caroline-state"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def selection_step(model, X, y, used_features=(), cv=3):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ==========\n",
    "        X: ndarray - training inputs\n",
    "        y: ndarray - training targets\n",
    "        used_features: - list of features\n",
    "        cv: int - number of folds\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "        scores - dictionary of scores\n",
    "    \"\"\"\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    # BEGIN Solution\n",
    "    unused_features = list(X.drop(columns=used_features).columns)\n",
    "    for feature in unused_features:\n",
    "        scores[feature] = (np.mean(cross_val_score(\n",
    "            model, X.loc[:, used_features + [feature]], y, cv=cv,\n",
    "            n_jobs=-1, scoring='neg_root_mean_squared_error')))\n",
    "\n",
    "    # END Solution\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9781013",
   "metadata": {
    "id": "laughing-patio"
   },
   "source": [
    "**1.3.2) Implement a forward greedy feature selection function (the one described in the pseudocode in subtask 1 above) that would**\n",
    "\n",
    "**- compute the model's \"quality\" over the currently *unused* features**\n",
    "\n",
    "**- find the feature, which has given the best score and add it to the list of the currently *used* features**\n",
    "\n",
    "**- if the model's quality has increased since the last round, add this feature to the list of the best features and  print the best score and the current best features list**\n",
    "\n",
    "**Do not forget to implement the early stopping.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b12487bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:03:01.027335Z",
     "start_time": "2022-03-06T13:03:01.013263Z"
    },
    "id": "pressed-worse"
   },
   "outputs": [],
   "source": [
    "def forward_steps(X, y, n_rounds, model):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ==========\n",
    "        X: ndarray - training inputs\n",
    "        y: ndarray - training targets\n",
    "        n_rounds: int - early stop when score doesn't increase n_rounds\n",
    "        model: sklearn model\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "        feat_best_list - list of features\n",
    "    \"\"\"\n",
    "\n",
    "    feat_best_list = []\n",
    "\n",
    "    # BEGIN Solution\n",
    "    best_quality = -np.infty\n",
    "    Round = 0\n",
    "\n",
    "    all_features = list(X.columns)\n",
    "    used_features = []\n",
    "    unused_features = all_features\n",
    "\n",
    "    while Round < n_rounds:\n",
    "        Round += 1\n",
    "\n",
    "        if len(unused_features) == 0:\n",
    "            break\n",
    "\n",
    "        scores = selection_step(model, X, y, used_features, cv=3)\n",
    "\n",
    "        new_feature = max(scores, key=lambda i: scores[i])\n",
    "        new_quality = scores[new_feature]\n",
    "        \n",
    "        used_features.append(new_feature)\n",
    "        unused_features.remove(new_feature)\n",
    "\n",
    "        if new_quality > best_quality:\n",
    "            feat_best_list.append(new_feature)\n",
    "            best_quality = new_quality\n",
    "            print(f\"best_quality = {best_quality}\")\n",
    "            Round = 0\n",
    "\n",
    "    # END Solution\n",
    "\n",
    "    return feat_best_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9314ca",
   "metadata": {
    "id": "geographic-holly"
   },
   "source": [
    "**1.3.3) Use the function implemented above + DecisionTreeRegressor to get the best features according to this algorithm. (HINT: Use ```n_rounds = 2```)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4224f263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:13:46.664294Z",
     "start_time": "2022-03-06T13:03:01.169294Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hazardous-retirement",
    "outputId": "81502f2d-f6fa-4497-d569-58605bfff430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_quality = -0.5227548498060216\n",
      "best_quality = -0.5005419000968402\n",
      "best_quality = -0.4965919641920604\n",
      "best_quality = -0.49491421346379655\n",
      "best_quality = -0.4933489956817529\n",
      "best_quality = -0.49251810588181577\n",
      "best_quality = -0.49168001104438686\n",
      "best_quality = -0.49101826071101223\n",
      "best_quality = -0.49050688717870045\n",
      "best_quality = -0.49002159756336905\n",
      "best_quality = -0.4894863291392415\n",
      "best_quality = -0.4892679838355356\n",
      "best_quality = -0.48906685054025095\n",
      "best_quality = -0.48899231968028783\n",
      "best_quality = -0.4888308873356384\n",
      "best_quality = -0.4886285021687134\n",
      "best_quality = -0.48858088960850027\n",
      "best_quality = -0.4884933852786231\n",
      "best_quality = -0.4883983230336981\n",
      "best_quality = -0.4883096826071484\n",
      "best_quality = -0.48823977181768363\n",
      "best_quality = -0.48812451103343624\n",
      "best_quality = -0.48810355806627803\n",
      "['full_sq', 'ecology_no data', 'sub_area_Nekrasovka', 'sub_area_Poselenie Vnukovskoe', 'modern_education_share_0', 'sub_area_Poselenie Novofedorovskoe', 'sub_area_Hamovniki', 'sub_area_Poselenie Filimonkovskoe', 'sub_area_Ivanovskoe', 'sub_area_Vojkovskoe', 'sub_area_Zapadnoe Degunino', 'sub_area_Solncevo', 'sub_area_Poselenie Moskovskij', 'sub_area_Horoshevskoe', 'sub_area_Poselenie Shherbinka', 'sub_area_Nagatinskij Zaton', 'sub_area_Birjulevo Zapadnoe', 'sub_area_Poselenie Pervomajskoe', 'sub_area_Juzhnoportovoe', 'sub_area_Poselenie Rogovskoe', \"sub_area_Sokol'niki\", \"sub_area_Zamoskvorech'e\", 'sub_area_Poselenie Voronovskoe']\n"
     ]
    }
   ],
   "source": [
    "### BEGIN Solution\n",
    "DTR = DecisionTreeRegressor(random_state = 0xC0FFEE)\n",
    "feat_best_list = forward_steps(X_train, y_train_log, n_rounds=2, model=DTR)\n",
    "print(feat_best_list)\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccdb011",
   "metadata": {
    "id": "contrary-packet"
   },
   "source": [
    "**1.3.4) Use Linear Regression, Ridge regression, Random forest and DecisionTree to get the RMSLE scores using these features. Remember the function you wrote earlier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81df8966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T13:13:47.662998Z",
     "start_time": "2022-03-06T13:13:46.949226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Methods</th>\n",
       "      <th>Train error</th>\n",
       "      <th>Test error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dtree</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFR</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Methods  Train error  Test error\n",
       "0  Linear Regression     0.001106    0.001153\n",
       "1              Lasso     0.001256    0.001302\n",
       "2              Ridge     0.001106    0.001152\n",
       "3              Dtree     0.000811    0.001002\n",
       "4                RFR     0.000817    0.000984"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN Solution\n",
    "df = comparison(X_train.loc[:,feat_best_list], y_train_log, X_test.loc[:,feat_best_list], y_test_log)\n",
    "df\n",
    "### END Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7d607",
   "metadata": {
    "id": "individual-rendering"
   },
   "source": [
    "## Task 2. Multi-Class Classification Strategies (1 point)\n",
    "In this task, you will deal with the multiclass classification problem for the Glass Classification Data. Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5822ab50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T15:06:11.462938Z",
     "start_time": "2022-03-06T15:06:11.432934Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "technical-trader",
    "outputId": "91043ffe-6127-441b-a6ae-58f111768d40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.51808</td>\n",
       "      <td>13.43</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.19</td>\n",
       "      <td>72.84</td>\n",
       "      <td>0.55</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.51593</td>\n",
       "      <td>13.09</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.52</td>\n",
       "      <td>73.10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.51813</td>\n",
       "      <td>13.43</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "52   1.51808  13.43  2.87  1.19  72.84  0.55  9.03  0.0  0.0     1\n",
       "72   1.51593  13.09  3.59  1.52  73.10  0.67  7.83  0.0  0.0     2\n",
       "132  1.51813  13.43  3.98  1.18  72.49  0.58  8.15  0.0  0.0     2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('glass.csv')\n",
    "X, y = data.drop('Type', axis=1), data.Type\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389de12",
   "metadata": {
    "id": "flying-region"
   },
   "source": [
    "The features of each glass object correspond to the fraction of the particular chemical element in the object. The target variable corresponds to the type of glass (6 classes).\n",
    "\n",
    "In this problem, you have to empirically compare the time complexity and performance of several multiclass labeling strategies for different algorithms. You must consider the following algorithms:\n",
    "* Single Decision Tree (depth 7)\n",
    "* Medium Random Forest (100 trees of depth 3)\n",
    "* KNearestNeighbors (5 neighbors)\n",
    "* Logistic Regression\n",
    "\n",
    "Note that all these algorithms by default support **multiclass labeling**. Nevertheless, we want you to compare this approach with **OneVSRest** and **OneVSOne** approaches applied to these algorithms. More precisely, for every pair (algorithm, approach) you are to perform a 5-fold cross-validation on the data and output the validation score and the computation time in the **table** form. Please note that you also have to choose the metric to optimize during CV (e.g. accuracy, balanced accuracy) on your own. \n",
    "\n",
    "After that, you are to answer the following questions:\n",
    "* Which metric did you choose to optimize during cross-validation and why? Explain\n",
    "* For which algorithms the usage of OneVSRest/OneVSOne approach provides significantly better performance without a significant increase in computation time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5eb256ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T16:02:56.677893Z",
     "start_time": "2022-03-06T16:02:39.097840Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores (CV=5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>K Nearest Neighbors</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiclass</td>\n",
       "      <td>-1.814507</td>\n",
       "      <td>-2.159911</td>\n",
       "      <td>-2.176966</td>\n",
       "      <td>-2.211960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneVsRest</td>\n",
       "      <td>-2.079623</td>\n",
       "      <td>-1.774086</td>\n",
       "      <td>-1.926135</td>\n",
       "      <td>-3.784496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneVsOne</td>\n",
       "      <td>-1.991141</td>\n",
       "      <td>-1.874529</td>\n",
       "      <td>-2.312182</td>\n",
       "      <td>-2.388704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method  Logistic  Random Forest  K Nearest Neighbors  Decision Tree\n",
       "0  Multiclass -1.814507      -2.159911            -2.176966      -2.211960\n",
       "1   OneVsRest -2.079623      -1.774086            -1.926135      -3.784496\n",
       "2    OneVsOne -1.991141      -1.874529            -2.312182      -2.388704"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Duration (CV=5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>K Nearest Neighbors</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiclass</td>\n",
       "      <td>0.197507</td>\n",
       "      <td>0.559794</td>\n",
       "      <td>0.071996</td>\n",
       "      <td>0.017998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneVsRest</td>\n",
       "      <td>0.632446</td>\n",
       "      <td>3.643611</td>\n",
       "      <td>0.326706</td>\n",
       "      <td>0.103953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneVsOne</td>\n",
       "      <td>1.499001</td>\n",
       "      <td>9.074016</td>\n",
       "      <td>1.335059</td>\n",
       "      <td>0.084972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method  Logistic  Random Forest  K Nearest Neighbors  Decision Tree\n",
       "0  Multiclass  0.197507       0.559794             0.071996       0.017998\n",
       "1   OneVsRest  0.632446       3.643611             0.326706       0.103953\n",
       "2    OneVsOne  1.499001       9.074016             1.335059       0.084972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "import time \n",
    "import copy\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "\n",
    "DtreeC = DecisionTreeClassifier( max_depth = 7, random_state=0x0C0FFEE )\n",
    "RforestC = RandomForestClassifier( n_estimators=100, max_depth=3,random_state=0x0C0FFEE, n_jobs=-1 )\n",
    "Knn = KNeighborsClassifier ( n_neighbors=5, n_jobs=-1 )\n",
    "LR = LogisticRegression (random_state=0x0C0FFEE, n_jobs=-1 )\n",
    "\n",
    "model_names = ['Logistic','Random Forest','K Nearest Neighbors','Decision Tree']\n",
    "models = [ LR, RforestC, Knn, DtreeC ]\n",
    "results = {'Method':['Multiclass','OneVsRest','OneVsOne'],\n",
    "         model_names[0]:[0]*3,\n",
    "         model_names[1]:[0]*3,\n",
    "         model_names[2]:[0]*3,\n",
    "         model_names[3]:[0]*3 }\n",
    "duration = copy.deepcopy(results)\n",
    "\n",
    "for model,model_name in zip(models, model_names):\n",
    "    \n",
    "    start = time.time()\n",
    "    results[model_name][0] = np.mean( cross_val_score(model,X,y,scoring='neg_mean_squared_error', cv = 5) )\n",
    "    end = time.time()\n",
    "    duration[model_name][0] = end-start\n",
    "      \n",
    "    start = time.time()\n",
    "    ovr = OneVsRestClassifier(model)\n",
    "    results[model_name][1] = np.mean( cross_val_score(ovr,X,y,scoring='neg_mean_squared_error', cv = 5) )\n",
    "    end = time.time()\n",
    "    duration[model_name][1] = end-start\n",
    "        \n",
    "    start = time.time()\n",
    "    ovo = OneVsOneClassifier(model)\n",
    "    results[model_name][2] = np.mean( cross_val_score(ovo,X,y,scoring='neg_mean_squared_error', cv = 5) )\n",
    "    end = time.time()\n",
    "    duration[model_name][2] = end-start\n",
    "    \n",
    "df_results = pd.DataFrame(data = results)\n",
    "df_duration = pd.DataFrame(data = duration)\n",
    "print(\"Cross Validation Scores (CV=5)\")\n",
    "display(df_results)\n",
    "print(\"Training Duration (CV=5)\")\n",
    "display(df_duration)\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928db63",
   "metadata": {
    "id": "married-preserve"
   },
   "source": [
    "**Which metric did you choose to optimize during cross validation and why? Explain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884c341",
   "metadata": {
    "id": "dutch-alfred"
   },
   "source": [
    "**Your text answer (do not delete this comment)**:\n",
    "\n",
    "I chose neg_mean_squared_error because we need to predict floating numbers and prediction doesn't have to match exactly with true value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745db20",
   "metadata": {
    "id": "elect-jerusalem"
   },
   "source": [
    "**For which algorithms the usage of OneVSRest/OneVSOne approach provides significantly better performance without a significant increase in computation time?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fde14",
   "metadata": {
    "id": "CH04Ord57RS4"
   },
   "source": [
    "**Your text answer (do not delete this comment)**:\n",
    "\n",
    "For neg_mean_squared_error only Random Forest and K Nearest Neighbors got increase in accuracy but the also got significant increase in computation time (5-7 times)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c334228",
   "metadata": {
    "id": "electric-matthew"
   },
   "source": [
    "# Task 3. Stacking (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0da52",
   "metadata": {
    "id": "third-liverpool"
   },
   "source": [
    "Stacking is an ensembling approach, which combines several algorithms (base models) to get better results. This is achieved by **a)** training the base models (any ML models) on the initial train data (or parts of the train data, see the paragraph below), **b)** training the meta-model (also an ML model) on the predictions of those base models.\n",
    "\n",
    "One of the main problems of stacking is overfitting. To avoid it, when evaluating the performance of the meta-model on the train set, the training data is divided into $ n $ folds, $ (n-1) $ of which are used for training the base models. The $ n $ -th fold is used for the overall prediction (calculating the meta-factor) in the following manner: the predictions on the $ n $ -th fold are made by the base models (already trained on the rest of the dataset), then these predictions on the $ n $ -th fold are fed as inputs to the meta-model.\n",
    "\n",
    "When evaluating the performance of the meta-model on the test set, there can be used various approaches$.^{[1]}$ For example, in order, to obtain meta-factors for the test data, the base classifiers can be retrained on the entire training set, since the problem of overfitting does not arise here. In other words, if we want to calculate the factors for the test set, we can safely use the training set to train the base classifiers (once again, as it is said in the paragraph above, if we want to calculate factors for the training set, then it is necessary to ensure that the classifier does not predict for those objects on which it has been trained).  \n",
    "\n",
    "You can read more details about stacking [blockpost](https://blog.statsbot.co/ensemble-learning-d1dcd548e936), [kaggle ensemble guide](https://mlwave.com/kaggle-ensembling-guide/).\n",
    "\n",
    "P.S. Stacking and Blending are two similar approaches to combining classifiers (ensembling). The difference is that Stacking uses out-of-fold predictions for the train set, and Blending uses a validation set to train the next layer ([source](quora.com/What-are-examples-of-blending-and-stacking-in-Machine-Learning)). Because they are so similar you can use any of them. \n",
    "\n",
    "[1] http://www.machinelearning.ru/wiki/images/5/56/Guschin2015Stacking.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69c6a9",
   "metadata": {
    "id": "recognized-guest"
   },
   "source": [
    "**Your task will be:**\n",
    "\n",
    "* Complete the ```meta_classfier``` function\n",
    "* Choose 6 different base models (base models can be any models that you know, and can differ between each other by different hyperparameters, models of ml, features e.t.c) and train them.\n",
    "* Report individual accuracy on the test set for each of the models.\n",
    "* Train the metaclassifier (in this case, once again, it is just an ML model) on the original dataset's features, report score on test.\n",
    "* Train the metaclassifier on the base models using $n$-fold cross-validation, as described above. Report the training score of the meta-classifier on the $ n $-th fold. Retrain the base models on the whole training set. Report the test score (accuracy) of the meta-classifier in this case.\n",
    "* Does stacking help to gain a better score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4ccad",
   "metadata": {
    "id": "incident-ceremony"
   },
   "source": [
    "For this task we will use the dataset fetch_covertype from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype). Split it train-test - 60/40.\n",
    "More details about this dataset you can find [here](https://archive.ics.uci.edu/ml/datasets/Covertype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f7029bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:14:44.307627Z",
     "start_time": "2022-03-07T05:14:43.652230Z"
    },
    "id": "banner-input"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "fc = sklearn.datasets.fetch_covtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49199573",
   "metadata": {
    "id": "collected-flash"
   },
   "source": [
    "Write meta classifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c70e16b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:15:03.010450Z",
     "start_time": "2022-03-07T05:15:02.993441Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = 7\n",
    "nrows = X_train.shape[0]\n",
    "nrows_in_fold = nrows // cv\n",
    "ind = [range(i * nrows_in_fold, (i + 1) * nrows_in_fold) for i in range(cv)]\n",
    "ind[-1] = range((cv - 1) * nrows_in_fold, nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea957a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:20:56.387611Z",
     "start_time": "2022-03-07T05:20:56.370604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348607, 54)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3173c068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:17:42.516737Z",
     "start_time": "2022-03-07T05:17:42.509741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348607,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c95fa7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:18:23.510277Z",
     "start_time": "2022-03-07T05:18:23.499295Z"
    }
   },
   "outputs": [],
   "source": [
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "L_train = y_train.shape[0]// cv\n",
    "L_test = L_train + y_train.shape[0] % cv\n",
    "assert L_test+L_train*(cv-1) == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "312f9239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:18:29.962752Z",
     "start_time": "2022-03-07T05:18:29.947756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49801"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a13a5096",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:19:01.623972Z",
     "start_time": "2022-03-07T05:19:01.603968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49801.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "348607/7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "983e04a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:57:02.254558Z",
     "start_time": "2022-03-07T05:57:02.232564Z"
    },
    "id": "brilliant-greensboro"
   },
   "outputs": [],
   "source": [
    "def meta_classifier(base_clfs, final_classifier, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Meta classifier prediction using stacking. \n",
    "    Input:\n",
    "    :param base_clfs: list,  base classifiers which will be stacked together.\n",
    "    :param final_classifier: estimator, a classifier which will be used to combine the base estimators. \n",
    "    :param X_train: numpy array or pandas table, train set.\n",
    "    :param y_train: numpy array or pandas table, target for train set.\n",
    "    :param X_test: numpy array or pandas table, test set.\n",
    "    :param cv: number of cross-validation folds.\n",
    "    \n",
    "    Output:\n",
    "    :param y_pred: numpy array or pandas table, prediction of meta classifier using stacking on test set.\n",
    "    :param final_classifier(optional): estimator, trained final_calssifier.\n",
    "    \n",
    "    \n",
    "    More details https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html\n",
    "    \n",
    "    \"\"\"\n",
    "    ### BEGIN Solution (do not delete this comment)\n",
    "    cv = len(base_clfs)+1\n",
    "    #split\n",
    "    assert X_train.shape[0] == y_train.shape[0]\n",
    "    L_train = y_train.shape[0]// cv\n",
    "    L_test = L_train + y_train.shape[0] % cv\n",
    "    assert L_test+L_train*(cv-1) == y_train.shape[0]\n",
    "\n",
    "    X_train_meta = np.empty((L_train,len(base_clfs)))\n",
    "    \n",
    "    X_test_local = X_train[(cv-1)*L_train:]\n",
    "    y_test_local = y_train[(cv-1)*L_train:]\n",
    "\n",
    "    assert len(X_test_local) == L_test\n",
    "    \n",
    "    \n",
    "    for i,clf in enumerate(base_clfs):\n",
    "        X_train_local = X_train[i*L_train:(i+1)*L_train]\n",
    "        assert len(X_train_local) == L_train\n",
    "        y_train_local = y_train[i*L_train:(i+1)*L_train]\n",
    "\n",
    "        clf.fit(X_train_local,y_train_local)\n",
    "        X_train_meta[:,i] = clf.predict(X_test_local)\n",
    "        \n",
    "    final_classifier.fit(X_train_meta, y_train_local)\n",
    "    meta_train_score = accuracy_score(y_train_local, final_classifier.predict(X_train_meta))\n",
    "    print(\"training score of the meta-classifier on the {}-th fold: {}\".format(cv,meta_train_score))\n",
    "    \n",
    "    # retraining base_clfs on the whole dataset\n",
    "    X_train_meta2 = np.empty((X_train.shape[0],len(base_clfs)))    \n",
    "    for i,clf in enumerate(base_clfs):\n",
    "        clf.fit(X_train,y_train)\n",
    "        X_train_meta2[:,i] = clf.predict(X_test)\n",
    "        \n",
    "    y_pred = final_classifier.predict(X_train_meta2)\n",
    "            \n",
    "    \n",
    "    ### END Solution (do not delete this comment)\n",
    "    return y_pred, final_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e3487",
   "metadata": {
    "id": "vfZmdicwORxq"
   },
   "source": [
    "### Subproblem 3.1 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4b0dc",
   "metadata": {
    "id": "incredible-wichita"
   },
   "source": [
    "**3.1.1) Chose 6 different base models (base models can be any models that you know,and can differ with each other by different hyperparameters,  models of ml, features e.t.c) and train them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "116dbfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:40:21.588990Z",
     "start_time": "2022-03-07T05:38:40.669548Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cleared-supply",
    "outputId": "6c3af77e-4cc3-41cf-85e1-c179b6332f02"
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "X = fc['data'] \n",
    "y = fc['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.6, shuffle=True, random_state=0xC0FFEE)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf1 = DecisionTreeClassifier( max_depth = 7, random_state=0x0C0FFEE )\n",
    "clf2 = RandomForestClassifier( n_estimators=100, max_depth=3,random_state=0x0C0FFEE, n_jobs=-1 )\n",
    "clf3 = DecisionTreeClassifier( max_depth = 20, random_state=0x0C0FFEE )\n",
    "clf4 = RandomForestClassifier( n_estimators=400, max_depth=5,random_state=0x0C0FFEE, n_jobs=-1 )\n",
    "clf5 = LogisticRegression(n_jobs=-1)\n",
    "clf6 = GaussianNB()\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5,clf6]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67394ba",
   "metadata": {
    "id": "streaming-crowd"
   },
   "source": [
    "**3.1.2) Report individual scores on test set. As a score use accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4175971b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:40:28.580352Z",
     "start_time": "2022-03-07T05:40:21.746939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "standing-breakdown",
    "outputId": "34a2ebd2-6a1c-40c4-afec-d5cab639cd46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf1    :DecisionTreeClassifier                       0.728     \n",
      "clf2    :RandomForestClassifier                       0.658     \n",
      "clf3    :DecisionTreeClassifier                       0.9006    \n",
      "clf4    :RandomForestClassifier                       0.6796    \n",
      "clf5    :LogisticRegression                           0.6237    \n",
      "clf6    :GaussianNB                                   0.4609    \n"
     ]
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = [0]*len(clfs)\n",
    "for i,clf in enumerate(clfs):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy[i] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    print('clf{:<5}:{:<45}{:<10.4}'.format(i+1,type(clf).__name__,accuracy[i]))\n",
    "\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7eb95",
   "metadata": {
    "id": "8CsZdyGPOj6E"
   },
   "source": [
    "### Subproblem 3.2 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2762be",
   "metadata": {
    "id": "adolescent-street"
   },
   "source": [
    "**3.2.1) Train metaclassifier (in this case, once again, it is just an ML model) on original dataset's features. And report score on test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5142c50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T16:16:35.650164Z",
     "start_time": "2022-03-06T16:16:29.530537Z"
    },
    "id": "lesbian-fields"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_clf:DecisionTreeClassifier                       0.9006    \n"
     ]
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "meta_clf = DecisionTreeClassifier( max_depth = 20, random_state=0x0C0FFEE ) #the same as clf3\n",
    "meta_clf.fit(X_train, y_train)\n",
    "meta_y_pred = meta_clf.predict(X_test)\n",
    "meta_accuracy = accuracy_score(y_true=y_test, y_pred=meta_y_pred)\n",
    "print('{:<8}:{:<45}{:<10.4}'.format('meta_clf',type(meta_clf).__name__,meta_accuracy))\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e534e7",
   "metadata": {
    "id": "horizontal-wallace"
   },
   "source": [
    "**3.2.2) Train the metaclassifier on the base models using $n$-fold cross-validation, as described above. Report the training score of the meta-classifier on the $ n $-th fold. Retrain the base models on the whole training set. Report the test score (accuracy) of the meta-classifier in this case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d894ba89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-07T05:57:22.415307Z",
     "start_time": "2022-03-07T05:57:05.206684Z"
    },
    "collapsed": true,
    "id": "renewable-concrete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score of the meta-classifier on the 7-th fold: 0.49436758298026146\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (232405,) into shape (348607,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/1331364991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### BEGIN Solution (do not delete this comment)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Metaclassifier score for retrained models: {accuracy_score(y_test, y_pred)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12216/1946470641.py\u001b[0m in \u001b[0;36mmeta_classifier\u001b[1;34m(base_clfs, final_classifier, X_train, X_test, y_train, cv)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mX_train_meta2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_meta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (232405,) into shape (348607,)"
     ]
    }
   ],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "\n",
    "y_pred, _ = meta_classifier(clfs, meta_clf, X_train, X_test, y_train,  7)\n",
    "print(f'Metaclassifier score for retrained models: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358d2df",
   "metadata": {
    "id": "printable-premium"
   },
   "source": [
    "**3.2.3) Report score(accuracy) on test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d031d40",
   "metadata": {
    "id": "auburn-easter"
   },
   "outputs": [],
   "source": [
    "### BEGIN Solution (do not delete this comment)\n",
    "\n",
    "### END Solution (do not delete this comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc151b5",
   "metadata": {
    "id": "premier-scout"
   },
   "source": [
    "**3.2.4) Does stacking helped to gain a better score?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085ef69",
   "metadata": {
    "id": "vSV5hJFR7RS-"
   },
   "source": [
    "**Your text answer (do not delete this comment)**:\n",
    "\n",
    "\\<write your answer\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed87454c",
   "metadata": {
    "id": "offensive-parts"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML_HW_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
